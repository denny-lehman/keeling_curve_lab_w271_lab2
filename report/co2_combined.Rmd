---
title: 'Statistical Methods for Discrete Response, Time Series, and Panel Data (W271): Lab 2'
subtitle: "Investigating the Keeling Curve and forecasting CO2 levels in Earth's atmosphere"
author: "Denny Lehman, Mingxi Liu, Aruna Bisht, Deepika Maddali"
# classoption: landscape
fontsize: 11pt
geometry: margin=1in
output: 
  pdf_document:
    toc: true
    number_sections: true
abstract: | 
  The Keeling curve is a [INTRODUCE THE CONCEPT IN ONE SENTENCE HERE and SHOW IMPORTANCE]. In this paper, the Keeling curve was analyzed from two perspectives, one from a researcher in 1998 and one from today (2023). From the perspective of 1998, EDA was performed from 1959 to 1997 and a linear time trend model was fit. After analysis of the assumptions, a cubic polynomial model was selected. Using the Box-Jenkins method, a SARIMA model was constructed and forecast into 2100. To contrast those models, we present the same analysis from the perspective of 2023. A modern data pipeline was constructed for CO2 data and the linear model and SARIMA model were compared to the actual CO2 levels. Both models under predicted CO2 with [ADD SOMETHING ON RMSE or OTHER HERE]. Finally, new models were fit on the 2023 a forecasted into the future with the goal of reviewing model predictions in a future analysis. 
---

# Introduction

We all know the debate about global warming and its connection to human activities. But to study this topic in a scientific way, we need reliable data. The Keeling Curve is a milestone in this aspect. It shows the ongoing increase in atmospheric carbon dioxide (CO2) concentrations over time. It is named after Charles David Keeling, the scientist who initiated and maintained the measurements. Keeling began monitoring atmospheric CO2 levels in 1958 at the Mauna Loa Observatory in Hawaii. He chose this location because it is remote and far from major sources of pollution, providing an ideal site to measure baseline CO2 concentrations. The Keeling Curve graphically represents the seasonal variations in atmospheric CO2 concentrations, as well as the long-term increasing trend. Keeling believes the seasonal pattern is a result of the Earth's vegetation absorbing CO2 during the growing season and releasing it during the dormant period, while the trend is primarily driven by human activities, particularly the burning of fossil fuels such as coal, oil, and natural gas, which release large amounts of CO2 into the atmosphere. The Keeling Curve is an important tool for scientists, policymakers, and the general public to understand the impact of human activities on the Earth's climate. It serves as a stark reminder of the need to reduce greenhouse gas emissions and address the causes and consequences of climate change.

Our research is based on the data from the Keeling Curve above. We first build a model based on data from 1959 to 1997 and make long-term predictions to the present. Then we combine the actual data with our prediction and discuss the implication of this comparison.

# Report from the Point of View of 1997 

## Data

The data measures the monthly average atmospheric CO2 concentration from 1959 to 1997, expressed in parts per million (ppm). It was initially collected by an infrared gas analyzer installed at Mauna Loa in Hawaii, which was one of the four analyzers installed by Keeling to evaluate whether there was a persistent increase in CO2 concentration. 

Fig.1 shows a clear long-term upward trend, which is confirmed by Fig.2 where the growth rate for each year is above zero. Fig.2 also suggests the average growth rate after 1970 is higher than that before 1970, although there's no evidence of accelerating growth. The ACF plots in Fig.3 and Fig.4 suggest the original data is non-stationary but its first difference is stationary. More formally, the KPSS tests below confirm the observations above.

```{r load packages, echo = FALSE, message = FALSE}


library(tidyverse)
library(ggplot2)
library(feasts)
library(tsibble)

## to use gg_season
library(feasts)

# ARIMA and STL
library(fable)

## To assemble multiple plots
library(gridExtra)

# for arima search
library("urca")

# for adf.test
library(tseries)

# stacked ggplots
library(patchwork)

library(latex2exp)
library(patchwork)
library(fable)
library(forecast)
library(tseries) # for adf.test
library(stargazer)
library(knitr) # for kable


theme_set(theme_minimal())
knitr::opts_chunk$set(dpi=1000)
```


```{r, echo = FALSE, message = FALSE}
co2_ts <- as_tsibble(co2) %>% filter(lubridate::year(index)<1998)

```

```{r, echo = FALSE, message = FALSE, warning=FALSE}
test_original=co2_ts |>
  features(value, unitroot_kpss)

test_1d=co2_ts |>
  mutate(d_value = difference(value)) |>
  features(d_value, unitroot_kpss)

test_results=round(as.data.frame(rbind(test_original,test_1d)),4)
rownames(test_results)=c("original","1st_difference")
kable(test_results,row.names=TRUE,caption = "KPSS test of orignal and 1st difference")
```


Another feature of the data is its robust seasonal pattern, with the peak in May and the bottom in October almost every year (see Fig.5). This seasonality can also be seen in Fig.4. Keeling believes it was the result of plant photosynthesis absorbing CO2 from the atmosphere.

Fig.4 is the histogram of the remaining or irregular components after removing the trend and the seasonal components from the data with STL^[Cleveland, R. B., Cleveland, W. S., McRae, J. E., & Terpenning, I. J. (1990). STL: A seasonal-trend decomposition procedure based on loess. Journal of Official Statistics, 6(1), 3â€“33.]. It looks like a normal distribution without obvious outliers.  


```{r, echo = FALSE, message = FALSE, warning=FALSE,fig.height=6}
p1 <- autoplot(co2_ts) +
  ggtitle("Fig.1 Atmospheric CO2 concentration\n monthly average, parts per million (ppm) ") +
  xlab(NULL) + ylab(NULL)+ 
  theme(text = element_text(size = 8)) 
p2 <- co2_ts %>% index_by(year = lubridate::year(index)) %>%
  summarise(annual_avg = mean(value)) %>%
  mutate(annual_growth = (annual_avg / lag(annual_avg, 1) - 1) * 100) %>%
  autoplot(.vars = annual_growth) +
  xlab(NULL) + ylab(NULL) +
  ggtitle("Fig.2 Annual growth rate of concentration, %")+ 
  theme(text = element_text(size = 8)) 
p3 <- co2_ts %>% ACF(value) %>% autoplot()+
  ggtitle("Fig.3 ACF of CO2 concentration")+ 
  theme(text = element_text(size = 8)) 
p4 <- co2_ts %>% ACF(difference(value)) %>% autoplot()+
  ggtitle("Fig.4 ACF of differenced CO2 concentration")+ 
  theme(text = element_text(size = 8)) 
p5 <- gg_season(co2_ts) +
  xlab(NULL) + ylab(NULL) +
  ggtitle("Fig.5 Seasonal plot of CO2 concentration")+ 
  theme(text = element_text(size = 8)) 
p6 <- co2_ts %>% model(STL(value ~ trend(window = 120) + season(window = "periodic"),
                        robust = TRUE)) %>%
  components() %>% pull(remainder) %>% gghistogram() +
  ggtitle("Fig.6 Histogram of irregular\n component by STL")+ 
  theme(text = element_text(size = 8)) 
(p1 | p2) / (p3 | p4)/ (p5 | p6)
```

## Linear model

Before building the model, we need to consider whether the data need a log transformation. Normally, a log transformation is required when the data shows exponential growth or the variance expands or shrinks over time. From Fig.1 and Fig.2 we can see the slope or the growth rate of the data is stable, which suggests the growth is more close to linear instead of exponential. Also, Fig.5 shows the difference between the annual high and the annual low almost remained the same over the years, suggesting the variance is nearly constant. Therefore, the log transformation is not necessary. We can first fit the original data with a linear time trend model as:

\begin{equation}
\label{eq:one}
\text{CO}_{2} = \beta_0 + \beta_1t + \epsilon_{t},
\end{equation} 

which gives the parameters as:

\begin{equation}
\label{eq:two}
\text{CO}_{2} = 311.5 + 0.11t + \epsilon_{t}
\end{equation}

This linear trend model implies that the $CO_2$ concentration increased by 0.11 ppm/month on average from 1959 to 1997. However, the residual plots in Fig.5 to Fig.7 suggest this simple linear trend model is not adequate in the following two aspects. 

First, the mean of the residual forms a "U" shape over time, suggesting a quadratic or higher-order polynomial time trend model may be more appropriate. For instance, the residual from a quadratic time trend model shows a more constant mean over time, as shown in Fig.8.

```{r, echo = FALSE, message = FALSE, warning=FALSE,fig.height=3}
fit <- co2_ts %>% model(
  linear_trend = TSLM(value ~ trend()),
  quadratic_trend = TSLM(value ~ trend() + I(trend() ^ 2))
)

resid_linear <-
  fit %>% dplyr::select(linear_trend) %>% residuals()
resid_quadratic <-
  fit %>% dplyr::select(quadratic_trend) %>% residuals()
p5 <-
  autoplot(resid_linear) + ggtitle("Fig.5 Residual of the linear trend model") +
  theme(text = element_text(size = 8))
p6 <-
  ggAcf(resid_linear) + ggtitle("Fig.6 ACF of the linear trend model residuals") +
  theme(text = element_text(size = 8))
p7 <-
  gghistogram(resid_linear %>% pull(.resid)) + ggtitle("Fig.7 Histogram of the linear\n trend model residuals") +
  theme(text = element_text(size = 8))
p8 <-
  autoplot(resid_quadratic) + ggtitle("Fig.8 Residual of the quadratic\n time trend model") +
  theme(text = element_text(size = 8))
(p5 | p6) / (p7 | p8)
```

In addition, the ACF plot in Fig.6 indicates strong seasonal patterns exist in the residuals, suggesting we should consider seasonal factors in the model. One solution is to include 11 dummy variables in the model to indicate the 12 months.

Based on the two points above, we compare the 2 candidates: a quadratic time trend model and a cubic one, as below.

\begin{equation}
\label{eq:three}
\text{Quadratic time trend: CO}_{2} = \alpha + \beta_0t + \beta_1t^2 +\sum_{i=1}^{11} \gamma_i Month_{it} + \epsilon_{t}
\end{equation} 
\begin{equation}
\label{eq:four}
\text{Cubic time trend: CO}_{2} = \alpha + \beta_0t + \beta_1t^2 + \beta_2t^3 + \sum_{i=1}^{11} \gamma_i Month_{it} + \epsilon_{t}
\end{equation} 

We use the data before 1991 as the training set and the rest as the validation set (similar to an 80-20 split). Our final choice of the model depends on the combination of 2 guidelines: 1) the information criterion (AICc, BIC) from the model fitting process and 2) the root mean square error (RMSE) of predictions on the validation set, which are listed in Table.1. Both information criterion (AICc, BIC) and RMSE favor the cubic model. Therefore, the cubic time trend model becomes our final choice. Its details are in the Appendix. We plot the forecast of this model until 2020 in Fig.7. One thing to note is that because the coefficient of the cubic term is negative, the predicted values will eventually begin to decrease when predicting the far future. In fact, we can see from Fig.7 that the predicted values have almost topped. This may be inappropriate extrapolation behavior. In that case, we should confine our predicting interval to the near term.

```{r, echo = FALSE, message = FALSE, warning=FALSE,fig.height=2}
co2_training = co2_ts %>% filter(lubridate::year(index) < 1991)
co2_valid = co2_ts %>% filter(lubridate::year(index) < 1998, lubridate::year(index) >= 1991)
fit_poly <- co2_training |>
  model(
    quadratic = TSLM(value ~ trend() + I(trend() ^ 2) + season()),
    cubic = TSLM(value ~ trend() + I(trend() ^ 2) + I(trend() ^ 3) +
                   season())
  )

vd <- forecast(fit_poly, h = 72)
fc_poly <- co2_ts %>%
  model(TSLM(value ~ trend() + I(trend() ^ 2) + I(trend() ^ 3) +
               season())) %>%
  forecast(h = 276)
model_ic = glance(fit_poly) %>%  dplyr::select(.model, AIC, AICc, BIC) %>% arrange(AICc)
vc_acc = fabletools::accuracy(vd, co2_valid) |> dplyr::select(.model, RMSE)
compare = cbind(model_ic, vc_acc['RMSE'])
kable(compare, caption = "Information Criterion of model fitting and RMSE of validation")
co2_ts %>%  autoplot(value) + autolayer(fc_poly) + ggtitle("Fig.7 Forecasts of CO2 level Up To 2020 Using Polynomial Trend Time Model") +
  theme(text = element_text(size = 8)) 
```

## ARIMA times series model 

We will use the Box Jenkins process to find the best ARIMA model via the following steps:

- Determine the appropriate model from EDA
- Find the best parameters
- Examine the residuals using diagnostic plots and statistical tests

The EDA revealed that the time series of CO2 had both autoregressive and seasonal components. Considering the ACF plot's low slow decay of autocorrelation, we expect differencing to be a key part of any time series model. In addition, we predict that the model will require seasonal components to model the 12 month cycle of seasonal variations. Therefore, we expect a seasonal arima model (SARIMA) with differencing and seasonality terms to be best.

In this section, we fit the best SARIMA model and analyze the results. We choose BIC as our information criteria for model selection. Simplicity is a desirable property in data science models to help explain the relationship between variables. We choose BIC as our information criteria because it penalizes complex models more than AIC or AICc and therefore selects more simple models with fewer parameters as the best ones. Lower BIC scores are better. 

```{r swap between denny and mingxi, echo=FALSE,  warning=FALSE}
df <- tsibble::as_tsibble(co2) %>%
  filter(index < lubridate::ymd('1998-01-01'))
```
```{r search for best ARIMA model, echo=FALSE,  warning=FALSE}
model.bic <-df %>%
  model(ARIMA(value ~ 0:1 + pdq(0:8,0:2,0:8) + PDQ(0:12,0:4,0:12), ic="bic", stepwise=F, greedy=F))

model.bic %>%
  report()

```
After searching over seasonal and non-seasonal P, D, and Q variables, the best model was an ARIMA(0,1,1)(1,1,2)[12] model with BIC score of 201.78. Next, we evaluate the model via diagnostic plots and statistical tests, concluding the Box Jenkins process.

 
```{r diagnostic plots, echo=FALSE, warning=FALSE, fig.height=5}
x <- model.bic %>% augment() # tsibble
residuals <- x$.resid # vector

par(mfrow=c(2,2))
plot(residuals,main = "Fig.8 Residuals of the SARIMA model")
acf(residuals, main="Fig.9 ACF plot of residuals")
pacf(residuals, main="Fig.10 PACF plot of residuals")
hist(residuals, main="Fig.11 histogram of residuals")

```

The residual plots (Fig 8-11) show that the SARIMA model was effective, with the residuals looking like stationary white noise (Fig 8). The time series has a mean of 0 with about constant variance, the ACF plot (Fig 9) shows no autocorrelation beyond the initial lag value. The PACF plot (Fig 10) appears to have a significant peak around the 3rd lag term, but this may be due to randomness, as it is barely passing the dashed blue line. The histogram (Fig 11) looks normally distributed at 0 with outliers creating a left tail. 

```{r test tests,  warning=FALSE, echo=FALSE, fig.height=3}
tsresid <- model.bic %>% augment() %>% select(.resid)
# adf test on residuals
dickey <- adf.test(tsresid$.resid, alternative = "stationary", k = 10)

# box-jund test
# null is data is independently distributed
resid.ts<-model.bic %>%
  augment() %>%
  select(.resid) %>%
  as.ts()
box_1 <- Box.test(resid.ts, lag = 1, type = "Ljung-Box")
box_10 <- Box.test(resid.ts, lag = 10, type = "Ljung-Box")

# adf.test(tsresid$.resid, alternative = "stationary", k = 10)
# Box.test(resid.ts, lag = 1, type = "Ljung-Box")
# Box.test(resid.ts, lag = 10, type = "Ljung-Box")

# qqplot on residuals, histogram on residuals
# p1 <- model.bic %>%
#   augment() %>%
#   select(.resid) %>% 
#   ggplot() +
#   geom_histogram(aes(x=.resid))+ ggtitle("Fig.12 Histogram plot of residuals from ARIMA") +
#   theme(text = element_text(size = 8)) 

p12 <- model.bic %>%
  augment() %>%
  select(.resid) %>% 
  ggplot(aes(sample=.resid)) +
  geom_qq() + stat_qq_line() + ggtitle("Fig.12 QQ plot of residuals") +
  theme(text = element_text(size = 8)) 

```
We test the residuals for stationarity with the Augmented Dickey Fuller test (ADF). The ADF test has the null hypothesis that the data is non stationary. With a p-value of `r dickey$p.value`, we reject the null hypothesis because there is enough evidence to say that the residuals are stationary.

The Box-Ljung test has the null hypothesis that the data presented is independently distributed. When presented with the residuals of the ARIMA model, the test had p-values of `r round(box_1$p.value,3)` and `r round(box_10$p.value,3)` for lag =1 and lag = 10 respectively. For both of those lags, we fail to reject the null hypothesis and conclude that the data is independently distributed.

Finally, we visually inspect the histogram of the residuals (Fig.11) and the QQ plot (Fig.12) to see if the residuals appear normally distributed. The histogram has the Gaussian bell shaped curve with a few outliers. The QQ plot shows that the data matches up with the normal distribution's quantiles. With these plots, we can confidently say that the residuals are visually normally distributed. 

To conclude, both diagnostic plots and statistical tests show that the residuals are stationary with mean 0, constant variance, and no autoregression or seasonality. We forecast our model to the year 2022 (Fig 13).

```{r co2 to 2022, echo=FALSE,  warning=FALSE, message=FALSE, fig.height=3}
p13 <- model.bic %>%
  forecast(h = (2022 - 1998) * 12) %>%
  autoplot(colour = "cornflowerblue") +
  autolayer(df, colour = "black") +
  labs(y = "CO2 ppm", title = "Fig.13 CO2 levels from 1959 to 2022") +
  guides(colour = guide_legend(title = "Forecast"))

p12 | p13
```

## Atmospheric CO2 growth Forecast
We use our model to make predictions on future levels of CO2, specifically 420 and 500 ppm. We will investigate the earliest, best guess, and latest ocurrance of these values. The earliest guess will be based on the first time the upper 95% confidence interval (CI) reaches the specified level and the latest guess will be the last time the value is within the lower 95% CI. The best guess will be the point estimate (mean) of the forecast. 

```{r forecast, echo=FALSE, warning=FALSE, message=FALSE}
fc_arima <- model.bic %>% forecast(h=1900)
fc <-fc_arima %>% mutate(upper=quantile(value,0.95),lower=quantile(value,0.05))
first_420 <- fc %>% filter(upper>=420)
first_420 <- min(first_420$index)
mean_420 <- fc %>% filter(.mean > 420)
mean_420 <- min(mean_420$index)
last_420 <- fc %>% filter(lower < 420)
last_420 <- max(last_420$index)

first_500 <- fc %>% filter(upper >= 500)
first_500 <- min(first_500$index)
mean_500 <- fc %>% filter(.mean > 500)
mean_500 <- min(mean_500$index)
last_500 <- fc %>% filter(lower<=500)
last_500 <- max(last_500$index)


d <- data.frame(
  'CO2 ppm level' = c("420 ppm", "500 ppm"),
  'earliest occurance' = c(first_420,first_500), 
  'point_estimate' = c(mean_420, mean_500),
  'final occurance' = c('never', 'never')
  # row.names = c('420 ppm','500 ppm')
  )
kable(x=d, caption = 'Predicted occurances of key CO2 levels')
```

Based on our model, the first time we could potentially see CO2 at 420 ppm is `r as.Date(first_420)` because that is when the upper 95% confidence interval (CI) of our model first reaches 420 ppm. The model's lower 95% CI hovers around 420, so there is no predicted final time. Knowing what we know today in 2023, 419 ppm was reached on May 2021, which was *before* our model's earliest guess. CO2 levels have risen faster than our model anticipated. This is a precursor to the analysis provided later in this paper. The first time our model predicts the earth to reach 500 ppm CO2 on `r as.Date(first_500)`, which is when the 95% CI reaches 500 ppm.  The model's lower 95% CI never reaches 500, so there is no predicted final time. 

Below is the prediction of our model to the year 2100. Confidence intervals are shown fanning outward. The error of the predictions compounds overtime which expands the confidence intervals into a funnel shape. The farther out in time from the recorded data points, the less accurate the prediction.


```{r forecast plot, echo=FALSE, warning=FALSE, message=FALSE, fig.height=3}
model.bic %>%
  forecast(h=(2100-1998)*12) %>%
autoplot(colour="cornflowerblue") +
autolayer(df, colour="black") +
  labs(y = "CO2 ppm",title = "Fig.14 CO2 levels from 1959 to 2100") +
  guides(colour = guide_legend(title = "Forecast"))
```




# Report from the Point of View of the Present 

## 0b.Introduction 

In our original 1997 paper, we made several predictions on the expected level atmospheric CO2. Currently, we will evaluate the accuracy of those predictions using time series analysis and extrapolate from present data to make predictions about the future.


## 1b.Data

A modern data pipeline was constructed to load both weekly and monthly CO2 data from January 1959 to June 2023. This will allow us to compare our forecasts in the previous section to the actual CO2 levels. The code for the pipeline can be found in the appendix.

## MOVE CODE  TO THE APPENDIX

```{r pull data from the global monitoring laboratory}
library(zoo)
if (!require("lubridate")) {
  install.packages("lubridate")
}

co2_url <- "https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_weekly_mlo.csv"
co2_monthly_url <- "https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.csv"


co2_present_raw=read.csv(co2_url,skip=51)
co2_present1 <- co2_present_raw %>% 
  mutate(time_index=make_date(year,month,day)) %>% 
  dplyr::select(time_index,average) %>%
  as_tsibble(index = time_index) %>%
  mutate(average =replace(average,average<=-999,NA)) %>%
  mutate(average = na.approx(average))


co2_present_raw=read.csv(co2_monthly_url,skip=56)

co2_present_month <- co2_present_raw %>% 
  mutate(time_index=make_date(year,month)) %>% 
  dplyr::select(time_index,average) %>%
  as_tsibble(index = time_index) %>%
  mutate(average =replace(average,average<=-999,NA)) %>%
  mutate(average = na.approx(average))


#read.csv(
#  url(co2_monthly_url,skip=56),
#  skip = 56,
#  header = TRUE,
#  col.names = c("year", "month", "decimal.date", "average", "deseasonalized","ndays", "sdev", "unc")) %>%
#  mutate(time_index = make_datetime(year, month)) %>%
#  mutate(time_index = yearmonth(time_index)) %>%
#  mutate(average = ifelse(average == -999.99, NA, average)) %>%
#  fill(average) %>%
#  filter(year < 2023) %>%
#  as_tsibble(index = time_index) -> co2_present_monthly


glimpse(co2_present1)
glimpse(co2_present_month)
```

```{r mingxis weekly load2}
library(zoo)
co2_present_raw=read.csv("https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_weekly_mlo.csv",skip=51)
```

```{r mingxis weekly load3}
co2_present <- co2_present_raw %>% 
  mutate(time_index=lubridate::make_date(year,month,day)) %>% 
  dplyr::select(time_index,average) %>%
  as_tsibble(index = time_index) %>%
  mutate(average =replace(average,average<=-999,NA)) %>%
  mutate(average = na.approx(average))
```

```{r   warning=FALSE, echo=FALSE, fig.align='center', fig.height=4, fig.width=10 }
# Get the overall CO2 values
value <- co2_present$average

# Create four plots
par(mfrow = c(2, 2))

# Plot the time series
plot(value, type = "l", col = "black", main = "Fig 20. CO2 time series",
     xlab = "Time", ylab = "CO2 rate")

# Plot the PACF
pacf(value, col = "black", main = "Fig 21. PACF of CO2")

# Plot the ACF
acf(value, col = "black", main = "Fig 22. ACF of CO2")

# Plot the distribution
hist(value, main = "Fig 23. CO2 Distribution",
     ylab = "Frequency", xlab = "CO2")
```

```{r ggplot version so that x axis shows time}

library(ggplot2)

p1 <- autoplot(co2_present1) +
  ggtitle("Fig.20 Atmospheric CO2 concentration\n monthly average, parts per million (ppm) ") +
  xlab(NULL) + ylab(NULL)+ 
  theme(text = element_text(size = 8)) 

p2 <- co2_present1 %>% index_by(year = lubridate::year(time_index)) %>%
  summarise(annual_avg = mean(value)) %>%
  mutate(annual_growth = (annual_avg / lag(annual_avg, 1) - 1) * 100) %>%
  autoplot(.vars = annual_growth) +
  xlab(NULL) + ylab(NULL) +
  ggtitle("Fig.2 Annual growth rate of concentration, %")+ 
  theme(text = element_text(size = 8)) 
p2 <- co2_present1 %>% PACF(value) %>% autoplot()+
  ggtitle("Fig.3 ACF of CO2 concentration")+ 
  theme(text = element_text(size = 8)) 
p3 <- co2_present1 %>% ACF(value) %>% autoplot()+
  ggtitle("Fig.3 ACF of CO2 concentration")+ 
  theme(text = element_text(size = 8)) 
p4 <- co2_present1 %>% ggplot() + 
  geom_histogram(aes(average))+
  ggtitle("Fig.4 Histogram")

(p1|p2)/(p3|p4)
```

The CO2 levels have continued to grow since 1997, but the growth has not been dramatic. Fig. 20 The time series plot shows that the CO2 levels have increased at a steady rate, with no major spikes or dips.

The most notable difference between the CO2 levels in 1997 and now is the distribution of the data. In 1997, the distribution was almost bimodal, meaning that there were two distinct peaks in the data. The distribution in Fig 22. shows more heavy-tailed pattern, meaning that there are more values at the high end of the distribution. This further suggests that there are more extreme CO2 levels now than there were in 1997.

## 2b.Compare linear model forecasts against realized CO2

## I'd recommend starting the forecast in 1998 
```{r, warning=FALSE, echo=FALSE, fig.align='center', fig.height=4, fig.width=10}

if (!require("fabletools")) {
  install.packages("fabletools")
}

co2_df <- tsibble::as_tsibble(co2) 

# the cubic model from part 2a
co2_df  %>%
  model(TSLM(value ~ trend() + I(trend()^2) + I(trend()^3) + 
               season())) -> co2_full_trend_fit

# initial code
fc_co2_2020 <- fabletools::forecast(co2_full_trend_fit, h=276)


# Create the forecast
forecast <- append(rep(NA, length=nrow(co2_present_month)-nrow(fc_co2_2020)),
                   fc_co2_2020$.mean)
# Create a data frame with the actuals and forecast
data.frame(time_index = co2_present_month$time_index, Actuals = co2_present_month$average, 
           Forecast = forecast) %>%
  pivot_longer(cols=c('Actuals', 'Forecast')) -> lm_vs_actuals

# Plot the actuals and forecast
lm_vs_actuals %>%
  ggplot(aes(x = time_index, y = value, color = name)) +
  geom_line() + 
  labs(y = 'CO2 Level', x = '', title = 'Fig. 23 Linear Model Forecast vs Realized CO2') 


# denny edit, to review. I started in 1998 instead of 2000
fc_co2_1998 <- fabletools::forecast(co2_full_trend_fit, h=(2023-1998)*12 +6)
# Create the forecast
forecast <- append(rep(NA, length=nrow(co2_present_month)-nrow(fc_co2_1998)),
                   fc_co2_1998$.mean)
# Create a data frame with the actuals and forecast
data.frame(time_index = co2_present_month$time_index, Actuals = co2_present_month$average, 
           Forecast = forecast) %>%
  pivot_longer(cols=c('Actuals', 'Forecast')) -> lm_vs_actuals

# Plot the actuals and forecast
lm_vs_actuals %>%
  ggplot(aes(x = time_index, y = value, color = name)) +
  geom_line() + 
  labs(y = 'CO2 Level', x = '', title = 'Fig. 23 Linear Model Forecast vs Realized CO2') 
```


The linear model in (Fig.23) forecast may not have capture the trend of the realized CO2 levels. The forecast appears to predict a stabilization in the CO2 levels, whereas the actual CO2 level trend increased.

## 3b.Compare ARIMA models forecasts against realized CO2 
```{r warning=FALSE, echo=FALSE, fig.align='center', fig.height=4, fig.width=10}

if (!require("fabletools")) {
  install.packages("fabletools")
}

co2_df <- tsibble::as_tsibble(co2) 

model.bic <- co2_df %>%
  model(ARIMA(value ~ 0 + pdq(0:10, 0:2, 0:10) + PDQ(0:10, 0:2, 0:10),
                       ic="bic", stepwise=F, greedy=F))


fc_co2_2022 <- fabletools::forecast(model.bic, h=(2023-1998)*12 + 6)


forecast <- append(rep(NA, length=nrow(co2_present_month)-nrow(fc_co2_2022)),
                   fc_co2_2022$.mean)
data.frame(time_index = co2_present_month$time_index, Actuals = co2_present_month$average, 
           Forecast = forecast) %>%
  pivot_longer(cols=c('Actuals', 'Forecast')) -> arima_vs_actuals

arima_vs_actuals %>%
  ggplot(aes(x = time_index, y = value, color = name)) +
  geom_line() + 
  labs(y = 'CO2 Level', x = '', title = 'Fig. 24 ARIMA Forecast vs Realized CO2') 

arima_vs_actuals %>% filter(name == 'Forecast' )
```

The ARIMA forecast(Fig.24) is much closer to the realized CO2 levels than the Linear Model forecast. The only difference observed, is that the ARIMA model appears to have forecasted a linear trend, while the realized CO2 levels followed an almost exponential growth.





## 4b.Evaluate the performance of 1997 linear and ARIMA models

```{r}
co2_present_monthly<-co2_present %>% index_by(index=yearmonth(time_index))%>%
  summarise(value=mean(average))
co2_present_monthly_since1998 <-co2_present_monthly%>%filter(year(index)>1997)
fc_poly_new <- co2_ts %>%
  model(TSLM(value ~ trend() + I(trend() ^ 2) + I(trend() ^ 3) +
               season())) %>%forecast(h=(2022-1997)*12+7)
fc_arima_new <- model.bic %>% forecast(h=(2022-1997)*12+7)

compared_data=data.frame(index=co2_present_monthly_since1998$index,actual=co2_present_monthly_since1998$value,forecast_poly=fc_poly_new$.mean,forecast_arima=fc_arima_new$.mean) %>% as_tsibble(index=index)

compared_data%>%pivot_longer(cols=c(actual,forecast_poly,forecast_arima)) %>% ggplot(aes(x=index,y=value,color=name))+geom_line()

compare_test=rbind(
  fabletools::accuracy(fc_poly_new,co2_present_monthly_since1998),
fabletools::accuracy(fc_arima_new,co2_present_monthly_since1998)

)
compare_test$.model=c("Best Polynomial","Best ARIMA")
kable(compare_test %>% dplyr::select(-.type,-MASE,-RMSSE))
```

Now we evaluate the accuracy for the best polynomial and ARIMA models built on the data till 1997. The forecast and actual values are plotted in Fig.X, and a quick glance would tell the both forecast are systematically lower than the actual data. More formally, the RMSE of prediction from the best polynomial model reaches `r round(compare_test$RMSE[1],2)`, and that of the best ARIMA model is `r round(compare_test$RMSE[2],2)`.



```{r do we need this?}
# co2_present <- co2_present_raw %>%
#   mutate(date = paste(year, month, day, sep = "-")) %>%
#   mutate(index = as.Date(date)) %>%
#   filter(year(date) >= 1997, average > 0) %>%
#   as_tsibble(index = index)
# 
# co2_present
```


```{r bunch of dataframes maybe not used}
# which if any do we need to keep?
# co2_present <- co2_present_raw %>% 
#   mutate(time_index=lubridate::make_date(year,month,day)) %>% 
#   dplyr::select(time_index,average) %>%
#   as_tsibble(index = time_index) %>%
#   mutate(average =replace(average,average<=-999,NA)) %>%
#   mutate(average = na.approx(average))
# 
# co2_present_raw1 <- co2_present_raw %>%
#   mutate(date = paste(year, month, day, sep = "-")) %>%
#   mutate(index = as.Date(date)) %>%
#   filter(year(date) >= 1997, average > 0) %>%
#   as_tsibble(index = index)
# 
# # broken
# # co2_present <- co2_present %>%
# #   mutate(date = paste(year, month, day, sep = "-")) %>%
# #   mutate(index = as.Date(date)) %>%
# #   filter(year(date) >= 1997, average > 0) %>%
# #   as_tsibble(index = index)
# 
# co2_present_yearly <- co2_present[c("year", "average")]
# co2_present_yearly_aggregate <- co2_present_yearly %>%
#   #mutate(year = year(index))%>%
#   group_by(year) %>%
#   summarize(average = mean(average))
# 
# co2_present_yearly_aggregate <- co2_present_yearly_aggregate %>%
#   arrange(desc(year))
# 
# # Extract the last two years for the test dataset
# test_data <- co2_present_yearly_aggregate %>%
#   slice(1:2)
# 
# # Extract the remaining data for the training dataset
# train_data <- co2_present_yearly_aggregate %>%
#   slice(-(1:2))
# 
# # co2_present_monthly
# co2_present_monthly_aggregate <- co2_present_monthly %>%
#   arrange(desc(index))
# 
# # Extract the last two years for the test dataset
# test_data_STL <- co2_present_monthly_aggregate %>%
#   slice(1:24)
# 
# # Extract the remaining data for the training dataset
# train_data_STL <- co2_present_monthly_aggregate %>%
#   slice(-(1:24))
# 
# co2_present_reduced <- co2_present%>%select(average , index)
# 
# co2_present_reduced1 <- as_tsibble(co2_present_reduced)
# 
# # Create the year-month combination as a new column
# co2_present_reduced2 <- co2_present_reduced1 %>%
#   mutate(yearmonth = yearmonth(index))
# 
# # Group by the year-month combination and calculate the mean of averages
# co2_present_yearlymonthly <- co2_present_reduced2 %>%
#   group_by(yearmonth) %>%
#   summarize(mean_average = mean(average))
# 
# # Extracted certain columns but getting Tibble object 
# 
# selected_data2 <- co2_present_yearlymonthly[c("yearmonth" ,"mean_average" )]
# 
# # Assuming your tsibble object is named "selected_data"
# grouped_data <- selected_data2 %>%
#   group_by(yearmonth) %>%
#   summarize(mean_average = mean(mean_average))
# 
# # Assuming your tibble is named "your_tibble"
# tsbl_data <- grouped_data %>%
#   as_tsibble(index = yearmonth)
```



## 5b. Train best models on present data
In the previous section, we conducted exploratory data analysis to visually assess the forecast of both the linear model and ARIMA model for atmospheric C02 levels. These models captured the historic trends and patterns effectively up to a certain point 1997. However as we moved from 1997, the forecasted lines started to deviate, making it challenging to determine which model better fits the data. To quantitatively evaluate the accuracy of the models, we conducted a formal evaluation using the Root Mean Squared Error (RMSE) test. Both the ARIMA and linear models were developed using data from 1974 to 1993. We used these models to forecast the atmospheric CO2 levels until 2023. Since models were built on a monthly dataset, the predictions we obtained were also on a monthly basis for the period from 1993 to 2023. 

To ensure a fair comparison of these predictions we aggregated the current dataset to a monthly level. The model performance of ARIMA model , after comparing its predictions with the current dataset, resulted in an RMSE of 51.66 On the other hand, the linear model which considered both the seasonal and trend components, had an RMSE of 14.037. It looks like that data has certain trend and pattern which are better captured by linear regression.




## STL    ####################




```{r , include = FALSE , fig.height=3 }

# Extracting the Trend, Seasonal, and Remainder components from the dataset after applying seasonal adjustment through # STL for the period Jan 1997 to Dec 2021

dcmp_add <- co2_present_monthly %>%
  model(stl = STL(value))

# are these graphs discussed at all? 
p33 <- components(dcmp_add) %>% autoplot()

p34<- components(dcmp_add)%>%
  ACF(remainder) %>%
  autoplot() + labs(title="Residuals additive decomposition")


```


```{r echo=FALSE}
# Seasonal adjustment vs Time

# is this graph needed?

dcmp_add %>%
  components() %>%
  as_tsibble() %>%
  ggplot() +
  geom_line(aes(x= index, y=season_adjust)) +
  labs(title = "Seasonal Adjustment vs. Year-Month",
       x = "Year-Month",
       y = "Seasonal Adjustment")

```


**Forecasts of Section 2 ARIMA model on Train Dataset [Seasonal adjusted] [Jan 2022 to Dec 2023]**
```{r include = FALSE}


seasonally_adjusted_STL <- dcmp_add %>%
  components() %>%
  as_tsibble() %>%
  select(index, season_adjust)

#seasonally_adjusted_STL[nrow(seasonally_adjusted_STL - 24): nrow(seasonally_adjusted_STL),]
rows <- nrow(seasonally_adjusted_STL)
test_data_seasonally_adjusted <- seasonally_adjusted_STL[(rows-24): rows,]
train_data_seasonally_adjusted <- seasonally_adjusted_STL[0: (rows-24),]

model.bic_monthlyyearly <-train_data_seasonally_adjusted %>%
  model(fable::ARIMA(season_adjust ~ 0:1 + pdq(0:3,0:2,0:3) + 
                       PDQ(0:10,0:3,0:10, period=12),
                     ic="bic", stepwise=F, greedy=F))

model.bic_monthlyyearly %>%
  report()
```




```{r include = FALSE}
# Forecasts of Section 2 ARIMA model on Train Dataset [Jan 2022 to Dec 2023]
test.size = (2024-2022)*12 # =24

model.forecasts_ARIMA_monthly_yearly <-forecast(model.bic_monthlyyearly, h=test.size)


# Merge the two data frames on the 'index' column, and handle missing values with 0
selected_df_monthly_yearly <- merge(model.forecasts_ARIMA_monthly_yearly, test_data_seasonally_adjusted, by = "index", all.x = TRUE) %>%
  select(index, season_adjust.y , .mean) %>%
  rename(predicted = .mean, current_value = season_adjust.y)

# Calculate the squared differences between 'predicted' and 'current_value'
selected_df_monthly_yearly$diff_squared <- (selected_df_monthly_yearly$predicted - selected_df_monthly_yearly$current_value)^2

# Calculate the RMSE
rmse_monthly_yearly <- sqrt(mean(selected_df_monthly_yearly$diff_squared))

# Print the RMSE
print(paste("ARIMA model Root Mean Squared Error (RMSE):", rmse_monthly_yearly))

```




**Forecasts of Section 2 LINEAR model on Train Dataset [Seasonal adjusted] [Jan 2022 to Dec 2023]**
```{r  echo = FALSE , fig.height=3}

# LINEAR model development on Training dataset for the period Jan 1997 to Dec 2021
fit_linear_season_adjusted_yeary_monthly <- train_data_seasonally_adjusted%>%model(model_trend =  TSLM(season_adjust ~ trend() + season() ))

# Forecasts of Section 2 LINEAR model on Test Dataset [Jan 2022 to Dec 2023]
test.size = (2024-2022)*12 #24

model.forecasts__season_linear_yearly_monthly <-forecast(fit_linear_season_adjusted_yeary_monthly, h=test.size)

p39 <- augment(fit_linear_season_adjusted_yeary_monthly)%>%ggplot(aes(x=index)) +
  geom_line(aes(y = season_adjust , color = "Data"))  + 
  geom_line(aes(y = .fitted , color = "Fitted")) + 
  labs( y= "Time" , title = " C02 Fit linear season")
p39

```


```{r}

# Merge the two data frames on the 'index' column, and handle missing values with 0
merged_df_yearly_monthly_linear <- merge(model.forecasts__season_linear_yearly_monthly, test_data_seasonally_adjusted, by = "index", all.x = TRUE)

# Select the desired columns and rename them if needed
selected_df_yearly_monthly_linear <- merged_df_yearly_monthly_linear %>%
  select(index, season_adjust.y , .mean) %>%
  rename(predicted = .mean, current_value = season_adjust.y)

# Calculate the squared differences between 'predicted' and 'current_value'
selected_df_yearly_monthly_linear$diff_squared <- (selected_df_yearly_monthly_linear$predicted - selected_df_yearly_monthly_linear$current_value)^2

# Calculate the RMSE
rmse_seasonal_yearly_monthly <- sqrt(mean(selected_df_yearly_monthly_linear$diff_squared))

# Print the RMSE
print(paste("Linear model Root Mean Squared Error (RMSE):", rmse_seasonal_yearly_monthly))
```

### NON-Season



```{r }
# NON-Seasonal adjusted
co2_present_reduced_weekly <- co2_present[c("time_index" ,"average")]
co2_present_reduced_weekly

```

```{r }
# NON-Seasonal adjusted
co2_present_reduced_weekly <- co2_present_reduced_weekly %>%
  mutate(yearweek = yearweek(time_index))
co2_present_reduced_weekly
```

```{r }
# Assuming your tsibble object is named "selected_data"
# NON-Seasonal adjusted

co2_present_reduced_weekly_group <- co2_present_reduced_weekly %>%
  group_by(yearweek) %>%
  summarize(mean_average = mean(average))
co2_present_reduced_weekly_group
```

```{r include = FALSE}
# NON-Seasonal adjusted

co2_present_reduced_weekly_group <- co2_present_reduced_weekly_group[c("yearweek" , "mean_average")]
co2_present_reduced_weekly_group

```


```{r }
# NON-Seasonal adjusted

library(tsibble)

# Currenlty in 
# Assuming your tibble is named "your_tibble"
co2_present_reduced_weekly_group <- co2_present_reduced_weekly_group %>%
  as_tsibble(index = yearweek)
co2_present_reduced_weekly_group
```


```{r include=FALSE}
# CO2 data Split into Train and Test Non-Seasonally Adjusted Dataset


co2_present_reduced_weekly_group <- co2_present_reduced_weekly_group %>%
  arrange(desc(yearweek))

# Extract the last two years for the test dataset
test_data_non_season <- co2_present_reduced_weekly_group %>%
  slice(1:96) %>% rename(index = yearweek)

# Extract the remaining data for the training dataset
train_data_non_season <- co2_present_reduced_weekly_group %>%
  slice(-(1:96))%>% rename(index = yearweek)


# Print the train datasets
print("Training Data:")
print(train_data_non_season)

# Print the test 
print("Test Data:")
print(test_data_non_season)

```


### ARIMA model development on Non-seasonally adjusted training datase
```{r include = FALSE}

# ARIMA model development on Non-seasonally adjusted training dataset for the period Jan 1997 to Dec 2021
# NON-Seasonal adjusted

library("fabletools")

# Filling gaps
train_data_non_season <- tsibble::fill_gaps(train_data_non_season)

# Developing model from non-seasonal adjusted dataset
model.bic_weekly_ARIMA <-train_data_non_season %>%
  model(fable::ARIMA(mean_average ~ 0:1 + pdq(0:4,0:2,0:4) + 
                       PDQ(0:5,0:3,0:5, period=12),
                     ic="bic", stepwise=F, greedy=F))

 model.bic_weekly_ARIMA %>%
  report()
```

```{r }
# Forecasts of Section 2 ARIMA model on Non-seasonally adjusted Train Dataset [Jan 2022 to Dec 2023]
# NON-Seasonal adjusted

test.size = 96

model.forecasts_ARIMA_weekly <-forecast(model.bic_weekly_ARIMA, h=test.size)
model.forecasts_ARIMA_weekly

```

```{r }

# Comparision of the ARIMA model prediction made in Section 2 for the period Jan 2022 to Dec 2023 with the Present actual CO2 values observed for the period Jan 2022 to Dec 2023
# NON-Seasonal adjusted


# Assuming model.forecasts and co2_present_monthly are your data frames

# Merge the two data frames on the 'index' column, and handle missing values with 0
merged_df_weekly <- merge(model.forecasts_ARIMA_weekly, test_data_non_season, by = "index", all.x = TRUE)
# merged_df_yearly[is.na(merged_df)] <- 0  # Replace missing values with 0

# Select the desired columns and rename them if needed
selected_df_weekly <- merged_df_weekly %>%
  select(index, mean_average.y , .mean) %>%
  rename(predicted = .mean, current_value = mean_average.y)

# Print the result
print(selected_df_weekly)
```

```{r echo=FALSE}
# #After comparision, Evaluate performance of LINEAR MODEL from Section 2 on the Present CO2 Dataset for the period Jan 2022 to Dec 2023
# NON-Seasonal adjusted

# Remove rows with missing values in 'predicted' or 'current_value'
# selected_df_linear <- selected_df_linear[complete.cases(selected_df_linear[c('predicted', 'current_value')]), ]

# Calculate the squared differences between 'predicted' and 'current_value'
selected_df_weekly$diff_squared <- (selected_df_weekly$predicted - selected_df_weekly$current_value)^2

# Calculate the RMSE
rmse_yearly_weekly_non_season <- sqrt(mean(selected_df_yearly$diff_squared))

# Print the RMSE
print(paste("Root Mean Squared Error (RMSE):", rmse_yearly_weekly_non_season))

```


```{r , echo = FALSE, fig.height=3 }
## Using NON- Seasonally Adjusted data for LINEAR
# LINEAR model development on NON- Seasonally Adjusted Training dataset for the period Jan 1997 to Dec 2021
# NON-Seasonal adjusted

train_data_non_season <- train_data_non_season%>%as_tsibble()
fit_linear_NON_season_weekly <- train_data_non_season%>%model(model_trend =  TSLM(mean_average ~ trend() + season() ))

p39 <- augment(fit_linear_NON_season_weekly)%>%ggplot(aes(x=yearweek)) +
  geom_line(aes(y = mean_average , color = "Data"))  + 
  geom_line(aes(y = .fitted , color = "Fitted")) + 
  labs( y= "Time" , title = " C02 Fit linear season")
p39

```

```{r include = FALSE}
# Forecasts of Section 2 LINEAR model on NON- Seasonally Adjusted Test Dataset [Jan 2022 to Dec 2023]

test.size = 96

model.forecasts_weekly_non_seasonal <-forecast(fit_linear_NON_season_weekly, h=test.size)
model.forecasts_weekly_non_seasonal  
```

```{r }
# Comparision of the LINEAR model prediction made in Section 2 NON- Seasonally Adjusted for the period Jan 2022 to Dec # 2023 with the Present actual CO2 values observed for the period Jan 2022 to Dec 2023

# Merging Predictions from ARIMA Model and Current Values for NON- Seasonally Adjusted Dataset

library(dplyr)

# Assuming model.forecasts and co2_present_monthly are your data frames

# Merge the two data frames on the 'index' column, and handle missing values with 0
merged_df_weekly_non_seasonal <- merge(model.forecasts_weekly_non_seasonal, test_data_non_season, by = "yearweek", all.x = TRUE)
# merged_df_yearly[is.na(merged_df)] <- 0  # Replace missing values with 0

# Select the desired columns and rename them if needed
selected_weekly_non_seasonal <- merged_df_weekly_non_seasonal %>%
  select(yearweek, mean_average.y , .mean) %>%
  rename(predicted = .mean, current_value = mean_average.y)

# Print the result
print(selected_weekly_non_seasonal)
```

```{r echo=FALSE}
# #After comparision, Evaluate performance of ARIMA MODEL from Section 2 on the Present CO2 Dataset for the period Jan 2022 to Dec 2023

# Remove rows with missing values in 'predicted' or 'current_value'
# selected_df_linear <- selected_df_linear[complete.cases(selected_df_linear[c('predicted', 'current_value')]), ]

# Calculate the squared differences between 'predicted' and 'current_value'
selected_weekly_non_seasonal$diff_squared <- (selected_weekly_non_seasonal$predicted - selected_weekly_non_seasonal$current_value)^2

# Calculate the RMSE
rmse_weekly_non_seasonal <- sqrt(mean(selected_weekly_non_seasonal$diff_squared))

# Print the RMSE
print(paste("Root Mean Squared Error (RMSE):", rmse_weekly_non_seasonal))


## ** The RMSE of the linear model is 1.78, but the RMSE of the ARIMA model is 0.11932, which is smaller. Therefore, the ARIMA model is a better model**

```

### (3 points) Task Part 6b: How bad could it get?
**With the non-seasonally adjusted data series, generate predictions for when atmospheric CO2 is expected to be at 420 ppm and 500 ppm levels for the first and final times (consider prediction intervals as well as point estimates in your answer). Generate a prediction for atmospheric CO2 levels in the year 2122. How confident are you that these will be accurate predictions?.Generate a prediction for atmospheric CO2 levels in the year 2100. How confident are you that these will be accurate predictions?**

**Observations**
The best model we derived from Part 5b was the ARIMA model. Utilizing this model, we projected CO2 levels on the original weekly dataset which is a non-seasonally adjusted data. Our analysis indicated that CO2 levels are predicted to reach 420 ppm in 2023, but are not expected to reach 500 ppm. We observed that in the year 3075, the upper boundary touched 500 ppm, but with low confidence. These predictions can be influenced by the data's aggregation level. For instance, weekly aggregated data may yield more vague predictions because the number of datapoints are larger resulting in higher noise and variability in data, whereas monthly aggregated data can provide slightly improved predictions. On examining the weekly level aggregated data, we noticed that the prediction boundary intervals curve downwards, which is not ideal because it captures too much noise and adds variability. However, with monthly level data, predictions are comparatively better, and the boundary intervals are narrower and upward. According to our analysis, the 500 ppm threshold is projected to be reached by the year 2050.

The predictions for 2122 is 425 with boundary limits of 310-555 in the weekly aggregated dataset. However, in the monthly aggregated dataset, the prediction for 2122 is 650 with narrower boundary levels.
Another factor that can impact these predictions is the evaluation metric used. In our analysis, we employed the Bayesian Information Criterion (BIC). If an alternative metric had been employed, the predictions might have varied. The use of BIC penalizes the data more, leading to a more conservative model selection that favors simpler models. As a result, the chosen model may be too simplistic to accurately capture the underlying patterns and relationships in the future unseen data. Hence, considering alternative evaluation metrics could potentially yield different or more accurate predictions.



```{r , echo=FALSE , fig.height=3}

# Year 2122 forcast and on Weekly Dataset

model_weekly_ARIMA_forecast <- fabletools::forecast(model.bic_weekly_ARIMA, h=5000)

model_weekly_ARIMA_forecast %>%
  autoplot(train_data_non_season) +
  labs(
    title = "Forecasts of weekly-aggregated CO2 levels up to 2122 using the ARIMA model",
    y = "CO2 Level", x = "Time"
  )
# 425 with boundary 310-555
```


```{r ,  fig.height=3}
# Year 2122 forcast and on Weekly Dataset

model_yearly_ARIMA_forecast <- fabletools::forecast(model.bic_monthlyyearly, h=1500)

model_yearly_ARIMA_forecast %>%
  autoplot(train_data_seasonally_adjusted) +
  labs(
    title = "Forecasts of CO2 level Up To 2122 using ARIMA model",
    y = "CO2 Level", x = "Time"
    
    # 650
  )
```



```{r}
test.size = 12784 # weekly time series unit

model.forecasts_ARIMA_weekly <-forecast(model.bic_weekly_ARIMA, h=test.size)
model.forecasts_ARIMA_weekly
```


```{r include=FALSE}
# Forecasts of Section2 ARIMA model for the period [Jan 2022 to Dec 2122]

test.size = 12784 # weekly time series unit

model.forecasts_ARIMA_weekly <-forecast(model.bic_weekly_ARIMA, h=test.size)
model.forecasts_ARIMA_weekly
```


```{r}
# predicted co2 value 420 
# Whether 420ppm CO2 present in data or not?
# period for [Jan 2022 to Dec 2122]

library(dplyr)

# Assuming your model.forecasts_ARIMA_weekly contains the columns 'date' and '.mean'

# Check if there is any value near 420 (within a range of +/- 10) in the .mean column
value_420ppm <- any(abs(model.forecasts_ARIMA_weekly$.mean - 420) <= 10)

# Print the result
print(value_420ppm)

# **420 ppm CO2 level is not present in the forecasted data until the year 2122. Hence upper and lower bound doesnt # exist either.**

```


 
```{r}
# predicted co2 value 500
# Whether 500ppm CO2 present in data or not?
# period for [Jan 2022 to Dec 2122]

library(dplyr)

# Assuming your model.forecasts_ARIMA_weekly contains the columns 'date' and '.mean'

# Check if there is any value near 420 (within a range of +/- 10) in the .mean column
value_500ppm <- any(abs(model.forecasts_ARIMA_weekly$.mean - 500) <= 10)

# Print the result
print(value_500ppm)

# **500 ppm CO2 level is not present in the forecasted data until the year 2122.Hence upper and lower bound doesnt # exist either.**
```


```{r }
# ## Confidence interval

model.forecasts_ARIMA_weekly_confidence_interval <-model.forecasts_ARIMA_weekly %>% mutate(upper=quantile(.mean,0.95),lower=quantile(.mean,0.05))
model.forecasts_ARIMA_weekly_confidence_interval

```












