---
title: 'Statistical Methods for Discrete Response, Time Series, and Panel Data (W271): Lab 2'
subtitle: "Investigating the Keeling Curve and forecasting CO2 levels in Earth's atmosphere"
author: "Denny Lehman, Mingxi Liu, Aruna Bisht, Deepika Maddali"
# classoption: landscape
fontsize: 11pt
geometry: margin=1in
output: 
  pdf_document:
    toc: true
    number_sections: true
abstract: | 
  The Keeling curve is a [INTRODUCE THE CONCEPT IN ONE SENTENCE HERE and SHOW IMPORTANCE]. In this paper, the Keeling curve was analyzed from two perspectives, one from a researcher in 1998 and one from today (2023). From the perspective of 1998, EDA was performed from 1959 to 1997 and a linear time trend model was fit. After analysis of the assumptions, a cubic polynomial model was selected. Using the Box-Jenkins method, a SARIMA model was constructed and forecast into 2100. To contrast those models, we present the same analysis from the perspective of 2023. A modern data pipeline was constructed for CO2 data and the linear model and SARIMA model were compared to the actual CO2 levels. Both models under predicted CO2 with [ADD SOMETHING ON RMSE or OTHER HERE]. Finally, new models were fit on the 2023 a forecasted into the future with the goal of reviewing model predictions in a future analysis. 
---

# Introduction

We all know the debate about global warming and its connection to human activities. But to study this topic in a scientific way, we need reliable data. The Keeling Curve is a milestone in this aspect. It shows the ongoing increase in atmospheric carbon dioxide (CO2) concentrations over time. It is named after Charles David Keeling, the scientist who initiated and maintained the measurements. Keeling began monitoring atmospheric CO2 levels in 1958 at the Mauna Loa Observatory in Hawaii. He chose this location because it is remote and far from major sources of pollution, providing an ideal site to measure baseline CO2 concentrations. The Keeling Curve graphically represents the seasonal variations in atmospheric CO2 concentrations, as well as the long-term increasing trend. Keeling believes the seasonal pattern is a result of the Earth's vegetation absorbing CO2 during the growing season and releasing it during the dormant period, while the trend is primarily driven by human activities, particularly the burning of fossil fuels such as coal, oil, and natural gas, which release large amounts of CO2 into the atmosphere. The Keeling Curve is an important tool for scientists, policymakers, and the general public to understand the impact of human activities on the Earth's climate. It serves as a stark reminder of the need to reduce greenhouse gas emissions and address the causes and consequences of climate change.

Our research is based on the data from the Keeling Curve above. We first build a model based on data from 1959 to 1997 and make long-term predictions to the present. Then we combine the actual data with our prediction and discuss the implication of this comparison.

# Report from the Point of View of 1997 

## Data

The data measures the monthly average atmospheric CO2 concentration from 1959 to 1997, expressed in parts per million (ppm). It was initially collected by an infrared gas analyzer installed at Mauna Loa in Hawaii, which was one of the four analyzers installed by Keeling to evaluate whether there was a persistent increase in CO2 concentration. 

Fig.1 shows a clear long-term upward trend, which is confirmed by Fig.2 where the growth rate for each year is above zero. Fig.2 also suggests the average growth rate after 1970 is higher than that before 1970, although there's no evidence of accelerating growth. The ACF plots in Fig.3 and Fig.4 suggest the original data is non-stationary but its first difference is stationary. More formally, the KPSS tests below confirm the observations above.

```{r load packages, echo = FALSE, message = FALSE}
library(tidyverse)
library(ggplot2)
library(feasts)
library(tsibble)

## to use gg_season
library(feasts)

# ARIMA and STL
library(fable)

## To assemble multiple plots
library(gridExtra)

# for arima search
library("urca")

# for adf.test
library(tseries)

# stacked ggplots
library(patchwork)

library(latex2exp)
library(patchwork)
library(fable)
library(forecast)
library(tseries) # for adf.test
library(stargazer)
library(knitr) # for kable
library(zoo)


theme_set(theme_minimal())
knitr::opts_chunk$set(dpi=1000)
```


```{r, echo = FALSE, message = FALSE}
co2_ts <- as_tsibble(co2) %>% filter(lubridate::year(index)<1998)

```

```{r, echo = FALSE, message = FALSE, warning=FALSE}
test_original=co2_ts |>
  features(value, unitroot_kpss)

test_1d=co2_ts |>
  mutate(d_value = difference(value)) |>
  features(d_value, unitroot_kpss)

test_results=round(as.data.frame(rbind(test_original,test_1d)),4)
rownames(test_results)=c("original","1st_difference")
kable(test_results,row.names=TRUE,caption = "KPSS test of orignal and 1st difference")
```


Another feature of the data is its robust seasonal pattern, with the peak in May and the bottom in October almost every year (see Fig.5). This seasonality can also be seen in Fig.4. Keeling believes it was the result of plant photosynthesis absorbing CO2 from the atmosphere.

Fig.4 is the histogram of the remaining or irregular components after removing the trend and the seasonal components from the data with STL^[Cleveland, R. B., Cleveland, W. S., McRae, J. E., & Terpenning, I. J. (1990). STL: A seasonal-trend decomposition procedure based on loess. Journal of Official Statistics, 6(1), 3â€“33.]. It looks like a normal distribution without obvious outliers.  


```{r, echo = FALSE, message = FALSE, warning=FALSE,fig.height=6}
p1 <- autoplot(co2_ts) +
  ggtitle("Fig.1 Atmospheric CO2 concentration\n monthly average, parts per million (ppm) ") +
  xlab(NULL) + ylab(NULL)+ 
  theme(text = element_text(size = 8)) 
p2 <- co2_ts %>% index_by(year = lubridate::year(index)) %>%
  summarise(annual_avg = mean(value)) %>%
  mutate(annual_growth = (annual_avg / lag(annual_avg, 1) - 1) * 100) %>%
  autoplot(.vars = annual_growth) +
  xlab(NULL) + ylab(NULL) +
  ggtitle("Fig.2 Annual growth rate of concentration, %")+ 
  theme(text = element_text(size = 8)) 
p3 <- co2_ts %>% ACF(value) %>% autoplot()+
  ggtitle("Fig.3 ACF of CO2 concentration")+ 
  theme(text = element_text(size = 8)) 
p4 <- co2_ts %>% ACF(difference(value)) %>% autoplot()+
  ggtitle("Fig.4 ACF of differenced CO2 concentration")+ 
  theme(text = element_text(size = 8)) 
p5 <- gg_season(co2_ts) +
  xlab(NULL) + ylab(NULL) +
  ggtitle("Fig.5 Seasonal plot of CO2 concentration")+ 
  theme(text = element_text(size = 8)) 
p6 <- co2_ts %>% model(STL(value ~ trend(window = 120) + season(window = "periodic"),
                        robust = TRUE)) %>%
  components() %>% pull(remainder) %>% gghistogram() +
  ggtitle("Fig.6 Histogram of irregular\n component by STL")+ 
  theme(text = element_text(size = 8)) 
(p1 | p2) / (p3 | p4)/ (p5 | p6)
```

## Linear model

Before building the model, we need to consider whether the data need a log transformation. Normally, a log transformation is required when the data shows exponential growth or the variance expands or shrinks over time. From Fig.1 and Fig.2 we can see the slope or the growth rate of the data is stable, which suggests the growth is more close to linear instead of exponential. Also, Fig.5 shows the difference between the annual high and the annual low almost remained the same over the years, suggesting the variance is nearly constant. Therefore, the log transformation is not necessary. We can first fit the original data with a linear time trend model as:

\begin{equation}
\label{eq:one}
\text{CO}_{2} = \beta_0 + \beta_1t + \epsilon_{t},
\end{equation} 

which gives the parameters as:

\begin{equation}
\label{eq:two}
\text{CO}_{2} = 311.5 + 0.11t + \epsilon_{t}
\end{equation}

This linear trend model implies that the $CO_2$ concentration increased by 0.11 ppm/month on average from 1959 to 1997. However, the residual plots in Fig.7 to Fig.10 suggest this simple linear trend model is not adequate in the following two aspects. 

First, the mean of the residual forms a "U" shape over time, suggesting a quadratic or higher-order polynomial time trend model may be more appropriate. For instance, the residual from a quadratic time trend model shows a more constant mean over time, as shown in Fig.10.

```{r, echo = FALSE, message = FALSE, warning=FALSE,fig.height=3}
fit <- co2_ts %>% model(
  linear_trend = TSLM(value ~ trend()),
  quadratic_trend = TSLM(value ~ trend() + I(trend() ^ 2))
)

resid_linear <-
  fit %>% dplyr::select(linear_trend) %>% residuals()
resid_quadratic <-
  fit %>% dplyr::select(quadratic_trend) %>% residuals()
p5 <-
  autoplot(resid_linear) + ggtitle("Fig.7 Residual of the linear trend model") +
  theme(text = element_text(size = 8))
p6 <-
  ggAcf(resid_linear) + ggtitle("Fig.8 ACF of the linear trend model residuals") +
  theme(text = element_text(size = 8))
p7 <-
  gghistogram(resid_linear %>% pull(.resid)) + ggtitle("Fig.9 Histogram of the linear\n trend model residuals") +
  theme(text = element_text(size = 8))
p8 <-
  autoplot(resid_quadratic) + ggtitle("Fig.10 Residual of the quadratic\n time trend model") +
  theme(text = element_text(size = 8))
(p5 | p6) / (p7 | p8)
```

In addition, the ACF plot in Fig.6 indicates strong seasonal patterns exist in the residuals, suggesting we should consider seasonal factors in the model. One solution is to include 11 dummy variables in the model to indicate the 12 months.

Based on the two points above, we compare the 2 candidates: a quadratic time trend model and a cubic one, as below.

\begin{equation}
\label{eq:three}
\text{Quadratic time trend: CO}_{2} = \alpha + \beta_0t + \beta_1t^2 +\sum_{i=1}^{11} \gamma_i Month_{it} + \epsilon_{t}
\end{equation} 
\begin{equation}
\label{eq:four}
\text{Cubic time trend: CO}_{2} = \alpha + \beta_0t + \beta_1t^2 + \beta_2t^3 + \sum_{i=1}^{11} \gamma_i Month_{it} + \epsilon_{t}
\end{equation} 

We use the data before 1991 as the training set and the rest as the validation set (similar to an 80-20 split). Our final choice of the model depends on the combination of 2 guidelines: 1) the information criterion (AICc, BIC) from the model fitting process and 2) the root mean square error (RMSE) of predictions on the validation set, which are listed in Table.1. Both information criterion (AICc, BIC) and RMSE favor the cubic model. Therefore, the cubic time trend model becomes our final choice. Its details are in the Appendix. We plot the forecast of this model until 2020 in Fig.9. One thing to note is that because the coefficient of the cubic term is negative, the predicted values will eventually begin to decrease when predicting the far future. In fact, we can see from Fig.11 that the predicted values have almost topped. This may be inappropriate extrapolation behavior. In that case, we should confine our predicting interval to the near term.

```{r, echo = FALSE, message = FALSE, warning=FALSE,fig.height=2}
co2_training = co2_ts %>% filter(lubridate::year(index) < 1991)
co2_valid = co2_ts %>% filter(lubridate::year(index) < 1998, lubridate::year(index) >= 1991)
fit_poly <- co2_training |>
  model(
    quadratic = TSLM(value ~ trend() + I(trend() ^ 2) + season()),
    cubic = TSLM(value ~ trend() + I(trend() ^ 2) + I(trend() ^ 3) +
                   season())
  )

vd <- forecast(fit_poly, h = 72)
fc_poly <- co2_ts %>%
  model(TSLM(value ~ trend() + I(trend() ^ 2) + I(trend() ^ 3) +
               season())) %>%
  forecast(h = 276)
model_ic = glance(fit_poly) %>%  dplyr::select(.model, AIC, AICc, BIC) %>% arrange(AICc)
vc_acc = fabletools::accuracy(vd, co2_valid) |> dplyr::select(.model, RMSE)
compare = cbind(model_ic, vc_acc['RMSE'])
kable(compare, caption = "Information Criterion of model fitting and RMSE of validation")
co2_ts %>%  autoplot(value) + autolayer(fc_poly) + ggtitle("Fig.11 Forecasts of CO2 level Up To 2020 Using Polynomial Trend Time Model") +
  theme(text = element_text(size = 8)) 
```

## ARIMA times series model 

We will use the Box Jenkins process to find the best ARIMA model via the following steps:

- Determine the appropriate model from EDA
- Find the best parameters
- Examine the residuals using diagnostic plots and statistical tests

The EDA revealed that the time series of CO2 had both autoregressive and seasonal components. Considering the ACF plot's low slow decay of autocorrelation, we expect differencing to be a key part of any time series model. In addition, we predict that the model will require seasonal components to model the 12 month cycle of seasonal variations. Therefore, we expect a seasonal arima model (SARIMA) with differencing and seasonality terms to be best.

In this section, we fit the best SARIMA model and analyze the results. We choose BIC as our information criteria for model selection. Simplicity is a desirable property in data science models to help explain the relationship between variables. We choose BIC as our information criteria because it penalizes complex models more than AIC or AICc and therefore selects more simple models with fewer parameters as the best ones. Lower BIC scores are better. 

```{r swap between denny and mingxi, echo=FALSE,  warning=FALSE}
df <- tsibble::as_tsibble(co2) %>%
  filter(index < lubridate::ymd('1998-01-01'))
```
```{r search for best ARIMA model, echo=FALSE,  warning=FALSE}
model.bic <-df %>%
  model(ARIMA(value ~ 0:1 + pdq(0:8,0:2,0:8) + PDQ(0:12,0:4,0:12), ic="bic", stepwise=F, greedy=F))

model.bic %>%
  report()

```
After searching over seasonal and non-seasonal P, D, and Q variables, the best model was an ARIMA(0,1,1)(1,1,2)[12] model with BIC score of 201.78. Next, we evaluate the model via diagnostic plots and statistical tests, concluding the Box Jenkins process.

 
```{r diagnostic plots, echo=FALSE, warning=FALSE, fig.height=5}
x <- model.bic %>% augment() # tsibble
residuals <- x$.resid # vector

par(mfrow=c(2,2))
plot(residuals,main = "Fig.12 Residuals of the SARIMA model")
acf(residuals, main="Fig.13 ACF plot of residuals")
pacf(residuals, main="Fig.14 PACF plot of residuals")
hist(residuals, main="Fig.15 histogram of residuals")

```

The residual plots (Fig 12-15) show that the SARIMA model was effective, with the residuals looking like stationary white noise (Fig 12). The time series has a mean of 0 with about constant variance, the ACF plot (Fig 13) shows no autocorrelation beyond the initial lag value. The PACF plot (Fig 14) appears to have a significant peak around the 3rd lag term, but this may be due to randomness, as it is barely passing the dashed blue line. The histogram (Fig 15) looks normally distributed at 0 with outliers creating a left tail. 

```{r test tests,  warning=FALSE, echo=FALSE, fig.height=3}
tsresid <- model.bic %>% augment() %>% select(.resid)
# adf test on residuals
dickey <- adf.test(tsresid$.resid, alternative = "stationary", k = 10)

# box-jund test
# null is data is independently distributed
resid.ts<-model.bic %>%
  augment() %>%
  select(.resid) %>%
  as.ts()
box_1 <- Box.test(resid.ts, lag = 1, type = "Ljung-Box")
box_10 <- Box.test(resid.ts, lag = 10, type = "Ljung-Box")

# adf.test(tsresid$.resid, alternative = "stationary", k = 10)
# Box.test(resid.ts, lag = 1, type = "Ljung-Box")
# Box.test(resid.ts, lag = 10, type = "Ljung-Box")

p12 <- model.bic %>%
  augment() %>%
  select(.resid) %>% 
  ggplot(aes(sample=.resid)) +
  geom_qq() + stat_qq_line() + ggtitle("Fig.17 QQ plot of residuals") +
  theme(text = element_text(size = 8)) 

```
We test the residuals for stationarity with the Augmented Dickey Fuller test (ADF). The ADF test has the null hypothesis that the data is non stationary. With a p-value of `r dickey$p.value`, we reject the null hypothesis because there is enough evidence to say that the residuals are stationary.

The Box-Ljung test has the null hypothesis that the data presented is independently distributed. When presented with the residuals of the ARIMA model, the test had p-values of `r round(box_1$p.value,3)` and `r round(box_10$p.value,3)` for lag =1 and lag = 10 respectively. For both of those lags, we fail to reject the null hypothesis and conclude that the data is independently distributed.

Finally, we visually inspect the histogram of the residuals (Fig.16) and the QQ plot (Fig.17) to see if the residuals appear normally distributed. The histogram has the Gaussian bell shaped curve with a few outliers. The QQ plot shows that the data matches up with the normal distribution's quantiles. With these plots, we can confidently say that the residuals are visually normally distributed. 

To conclude, both diagnostic plots and statistical tests show that the residuals are stationary with mean 0, constant variance, and no autoregression or seasonality. We forecast our model to the year 2022 (Fig 18).

```{r co2 to 2022, echo=FALSE,  warning=FALSE, message=FALSE, fig.height=3}
p13 <- model.bic %>%
  forecast(h = (2022 - 1998) * 12) %>%
  autoplot(colour = "cornflowerblue") +
  autolayer(df, colour = "black") +
  labs(y = "CO2 ppm", title = "Fig.18 CO2 levels from 1959 to 2022") +
  guides(colour = guide_legend(title = "Forecast"))

p12 | p13
```

## Atmospheric CO2 growth Forecast
We use our model to make predictions on future levels of CO2, specifically 420 and 500 ppm. We will investigate the earliest, best guess, and latest ocurrance of these values. The earliest guess will be based on the first time the upper 95% confidence interval (CI) reaches the specified level and the latest guess will be the last time the value is within the lower 95% CI. The best guess will be the point estimate (mean) of the forecast. 

```{r forecast, echo=FALSE, warning=FALSE, message=FALSE}
fc_arima <- model.bic %>% forecast(h=1900)
fc <-fc_arima %>% mutate(upper=quantile(value,0.95),lower=quantile(value,0.05))
first_420 <- fc %>% filter(upper>=420)
first_420 <- min(first_420$index)
mean_420 <- fc %>% filter(.mean > 420)
mean_420 <- min(mean_420$index)
last_420 <- fc %>% filter(lower < 420)
last_420 <- max(last_420$index)

first_500 <- fc %>% filter(upper >= 500)
first_500 <- min(first_500$index)
mean_500 <- fc %>% filter(.mean > 500)
mean_500 <- min(mean_500$index)
last_500 <- fc %>% filter(lower<=500)
last_500 <- max(last_500$index)


d <- data.frame(
  'CO2 ppm level' = c("420 ppm", "500 ppm"),
  'earliest occurance' = c(first_420,first_500), 
  'point_estimate' = c(mean_420, mean_500),
  'final occurance' = c('never', 'never')
  # row.names = c('420 ppm','500 ppm')
  )
kable(x=d, caption = 'Predicted occurances of key CO2 levels')
```

Based on our model, the first time we could potentially see CO2 at 420 ppm is `r as.Date(first_420)` because that is when the upper 95% confidence interval (CI) of our model first reaches 420 ppm. The model's lower 95% CI hovers around 420, so there is no predicted final time. Knowing what we know today in 2023, 419 ppm was reached on May 2021, which was *before* our model's earliest guess. CO2 levels have risen faster than our model anticipated. This is a precursor to the analysis provided later in this paper. The first time our model predicts the earth to reach 500 ppm CO2 on `r as.Date(first_500)`, which is when the 95% CI reaches 500 ppm.  The model's lower 95% CI never reaches 500, so there is no predicted final time. 

Below is the prediction of our model to the year 2100. Confidence intervals are shown fanning outward. The error of the predictions compounds overtime which expands the confidence intervals into a funnel shape. The farther out in time from the recorded data points, the less accurate the prediction.


```{r forecast plot, echo=FALSE, warning=FALSE, message=FALSE, fig.height=3}
model.bic %>%
  forecast(h=(2100-1998)*12) %>%
autoplot(colour="cornflowerblue") +
autolayer(df, colour="black") +
  labs(y = "CO2 ppm",title = "Fig.19 CO2 levels from 1959 to 2100") +
  guides(colour = guide_legend(title = "Forecast"))
```




# Report from the Point of View of the Present 

## 0b.Introduction 

In our original 1997 paper, we made several predictions on the expected level atmospheric CO2. Currently, we will evaluate the accuracy of those predictions using time series analysis and extrapolate from present data to make predictions about the future.


## 1b.Data

A modern data pipeline was constructed to load both weekly and monthly CO2 data from January 1959 to June 2023. This will allow us to compare our forecasts in the previous section to the actual CO2 levels. The code for the pipeline can be found in the appendix.

## MOVE CODE  TO THE APPENDIX


```{r weekly load, include = FALSE}
co2_present_raw=read.csv("https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_weekly_mlo.csv",skip=51)
co2_present <- co2_present_raw %>% 
  mutate(time_index=lubridate::make_date(year,month,day)) %>% 
  dplyr::select(time_index,average) %>%
  as_tsibble(index = time_index) %>%
  mutate(average =replace(average,average<=-999,NA)) %>%
  mutate(average = na.approx(average))
```

```{r monthly load, include = FALSE}

co2_present_monthly_raw <- "https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.csv"

co2_present_raw=read.csv(co2_present_monthly_raw,skip=56)

co2_present_month <- co2_present_raw %>% 
  mutate(time_index=lubridate::make_date(year,month)) %>% 
  dplyr::select(time_index,average) %>%
  as_tsibble(index = time_index) %>%
  mutate(average =replace(average,average<=-999,NA)) %>%
  mutate(average = na.approx(average))



glimpse(co2_present)
glimpse(co2_present_month)
```



# ADJUSTED THE FIGURE SIZE

```{r ggplot version so that x axis shows time}


p1 <- autoplot(co2_present) +
  ggtitle("Fig.20 Atmospheric CO2 concentration\n monthly average, parts per million (ppm) ") +
  xlab(NULL) + ylab(NULL)+ 
  theme(text = element_text(size = 8)) 
p2 <- co2_present %>% index_by(year = lubridate::year(time_index)) %>%
  summarise(annual_avg = mean(average)) %>%
  mutate(annual_growth = (annual_avg / lag(annual_avg, 1) - 1) * 100) %>%
  autoplot(.vars = annual_growth) +
  xlab(NULL) + ylab(NULL) +
  ggtitle("Fig.21 Annual growth rate of concentration, %")+ 
  theme(text = element_text(size = 8)) 
p2 <- co2_present %>% PACF(average) %>% autoplot()+
  ggtitle("Fig.22 ACF of CO2 concentration")+ 
  theme(text = element_text(size = 8)) 
p3 <- co2_present %>% ACF(average) %>% autoplot()+
  ggtitle("Fig.23 ACF of CO2 concentration")+ 
  theme(text = element_text(size = 8)) 
p4 <- co2_present %>% ggplot() + 
  geom_histogram(aes(average))+
  ggtitle("Fig.24 Histogram")

(p1|p2)/(p3|p4)

```

The CO2 levels have continued to grow since 1997, but the growth has not been dramatic. Fig. 20 The time series plot shows that the CO2 levels have increased at a steady rate, with no major spikes or dips.

The most notable difference between the CO2 levels in 1997 and now is the distribution of the data. In 1997, the distribution was almost bimodal, meaning that there were two distinct peaks in the data. The distribution in Fig 24. shows more heavy-tailed pattern, meaning that there are more values at the high end of the distribution. This further suggests that there are more extreme CO2 levels now than there were in 1997.

## 2b.Compare linear model forecasts against realized CO2

## I'd recommend starting the forecast in 1998 
```{r, warning=FALSE, echo=FALSE, fig.align='center', fig.height=4, fig.width=10}

co2_df <- tsibble::as_tsibble(co2) 

# the cubic model from part 2a
co2_df  %>%
  model(TSLM(value ~ trend() + I(trend()^2) + I(trend()^3) + 
               season())) -> co2_full_trend_fit




# Pulling the data from  1998 until 2023
fc_co2_1998 <- fabletools::forecast(co2_full_trend_fit, h=(2023-1998)*12 +6)
# Create the forecast
forecast <- append(rep(NA, length=nrow(co2_present_month)-nrow(fc_co2_1998)),
                   fc_co2_1998$.mean)
# Create a data frame with the actuals and forecast
data.frame(time_index = co2_present_month$time_index, Actuals = co2_present_month$average, 
           Forecast = forecast) %>%
  pivot_longer(cols=c('Actuals', 'Forecast')) -> lm_vs_actuals

# Plot the actuals and forecast
lm_vs_actuals %>%
  ggplot(aes(x = time_index, y = value, color = name)) +
  geom_line() + 
  labs(y = 'CO2 Level', x = '', title = 'Fig. 25 Linear Model Forecast vs Realized CO2') 
```


The linear model in (Fig.25) forecast may not have capture the trend of the realized CO2 levels. The forecast appears to predict a stabilization in the CO2 levels, whereas the actual CO2 level trend increased.

## 3b.Compare ARIMA models forecasts against realized CO2 
```{r warning=FALSE, echo=FALSE, fig.align='center', fig.height=4, fig.width=10}

co2_df <- tsibble::as_tsibble(co2) 

model.bic <- co2_df %>%
  model(ARIMA(value ~ 0 + pdq(0:10, 0:2, 0:10) + PDQ(0:10, 0:2, 0:10),
                       ic="bic", stepwise=F, greedy=F))


fc_co2_2022 <- fabletools::forecast(model.bic, h=(2023-1998)*12 + 6)


forecast <- append(rep(NA, length=nrow(co2_present_month)-nrow(fc_co2_2022)),
                   fc_co2_2022$.mean)
data.frame(time_index = co2_present_month$time_index, Actuals = co2_present_month$average, 
           Forecast = forecast) %>%
  pivot_longer(cols=c('Actuals', 'Forecast')) -> arima_vs_actuals

arima_vs_actuals %>%
  ggplot(aes(x = time_index, y = value, color = name)) +
  geom_line() + 
  labs(y = 'CO2 Level', x = '', title = 'Fig. 26 ARIMA Forecast vs Realized CO2') 
```

The ARIMA forecast(Fig.26) is much closer to the realized CO2 levels than the Linear Model forecast. The only difference observed, is that the ARIMA model appears to have forecasted a linear trend, while the realized CO2 levels followed an almost exponential growth.


## 4b.Evaluate the performance of 1997 linear and ARIMA models

```{r}
co2_present_monthly<-co2_present %>% index_by(index=yearmonth(time_index))%>%
  summarise(value=mean(average))
co2_present_monthly_since1998 <-co2_present_monthly%>%filter(lubridate::year(index)>1997)
fc_poly_new <- co2_ts %>%
  model(TSLM(value ~ trend() + I(trend() ^ 2) + I(trend() ^ 3) +
               season())) %>%forecast(h=(2022-1997)*12+7)
fc_arima_new <- model.bic %>% forecast(h=(2022-1997)*12+7)

compared_data=data.frame(index=co2_present_monthly_since1998$index,actual=co2_present_monthly_since1998$value,forecast_poly=fc_poly_new$.mean,forecast_arima=fc_arima_new$.mean) %>% as_tsibble(index=index)

compared_data%>%pivot_longer(cols=c(actual,forecast_poly,forecast_arima)) %>% ggplot(aes(x=index,y=value,color=name))+geom_line()

compare_test=rbind(
  fabletools::accuracy(fc_poly_new,co2_present_monthly_since1998),
fabletools::accuracy(fc_arima_new,co2_present_monthly_since1998)

)
compare_test$.model=c("Best Polynomial","Best ARIMA")
kable(compare_test %>% dplyr::select(-.type,-MASE,-RMSSE))
```

Now we evaluate the accuracy for the best polynomial and ARIMA models built on the data till 1997. The forecast and actual values are plotted in Fig.X, and a quick glance would tell the both forecast are systematically lower than the actual data. More formally, the RMSE of prediction from the best polynomial model reaches `r round(compare_test$RMSE[1],2)`, and that of the best ARIMA model is `r round(compare_test$RMSE[2],2)`.


## 5b. Train best models on present data
In the previous section, we performed a comprehensive evaluation of models trained on 1997 dataset with the focus on long term forecasting 1998 to 2023 and got high residual error. However, for long term forecasting, utilizing seasonally adjusted data becomes more appropriate. To accomplish this we applied the STL method, which effectively decomposes the time series and provides us with seasonal adjusted data. This dataset was subsequently split into training (1997 to 2021) and test (2021 to 2023) sets to assess model performance.

The ARIMA models were trained on the training dataset and evaluated on the test dataset, yielding an RMSE value of 0.83. Similarly we conducted a parallel analysis on the non seasonal adjusted data, resulting in an RMSE value of 0.11. Interestingly, the non-seasonally adjusted ARIMA model showcased slightly better performance than its seasonally adjusted counterpart.

During the training process, we employed a grid search, exploring various parameter combinations (p, d, q) ranging from (0:8, 0:2, 0:8) and seasonal parameter combinations (P, D, Q) spanning from (0:12, 0:4, 0:12). The final selected ARIMA model was (0,1,1)(4,0,0)[12], indicating the implementation of differencing once for stationarity and incorporating one lag of forecast errors. This model demonstrated improved performance on the out-of-sample test dataset compared to the ARIMA model built in the previous section. This improvement in predictive capabilities can be attributed to the inclusion of more recent training data from 1997 to 2020, which allowed the model to forecast the immediate future (2021 to 2023) more accurately. Also, the ARIMA model performs well both on in-sample and out-sample, indicating that model is flexible and able to predict accurately and not overfitting.
Additionally, we compared the non-seasonally adjusted ARIMA model with a polynomial linear model trained on seasonally adjusted data. The RMSE value for the polynomial linear model was 1.7, whereas the non-seasonally adjusted ARIMA model achieved an RMSE of 0.14. The non-seasonally adjusted ARIMA model showcased superior performance in predicting the immediate future and effectively capturing the seasonal pattern. Also, as seen from the EDA, the seasonal pattern is stable in this data. Conversely, the polynomial linear model on seasonally adjusted data is better for predicting long-term trends and not as effective in capturing seasonal variations. Overall, our analysis highlighted the significance of selecting the appropriate modeling approach based on the forecasting requirements and the nature of the data.



```{r seasonal decomposition, include = FALSE }
# Extracting the Trend, Seasonal, and Remainder components from the dataset after applying seasonal adjustment through # STL for the period Jan 1997 to Dec 2021
dcmp_add <- co2_present_monthly %>%
  model(stl = STL(value))
```

```{r split train and test data seasonally adjusted, include = FALSE}
seasonally_adjusted_STL <- dcmp_add %>%
  components() %>%
  as_tsibble() %>%
  select(index, season_adjust)

rows <- nrow(seasonally_adjusted_STL)
test_data_seasonally_adjusted <- seasonally_adjusted_STL[(rows-24): rows,]
train_data_seasonally_adjusted <- seasonally_adjusted_STL[0: (rows-24),]
```
```{r train test split for non seasonal data, include=FALSE}
# CO2 data Split into Train and Test Non-Seasonally Adjusted Dataset
co2_present %>% 
  mutate(time_index = yearweek(time_index)) %>% # converts to 2023 W27 format
  summarize(value = mean(average)) %>%
  arrange(desc(time_index)) -> co2_present_reduced_weekly_group

# Extract the last two years for the test dataset
test_data_non_season <- co2_present_reduced_weekly_group %>%
  slice(1:96)

# Extract the remaining data for the training dataset
train_data_non_season <- co2_present_reduced_weekly_group %>%
  slice(-(1:96))

# Filling gaps
train_data_non_season <- tsibble::fill_gaps(train_data_non_season)

```

```{r train the ARIMA seasonally adjusted, include=FALSE }
model.bic_monthlyyearly <-train_data_seasonally_adjusted %>%
  model(fable::ARIMA(season_adjust ~ 0:1 + pdq(0:3,0:2,0:3) + 
                       PDQ(0:8,0:3,0:8, period=12),
                     ic="bic", stepwise=F, greedy=F))

model.bic_monthlyyearly %>% 
  report()

```




```{r forecast ARMIA seasonal adjusted, include = FALSE}
# Forecasts of Section 2 ARIMA model on Train Dataset [Jan 2022 to Dec 2023]
test.size = (2024-2022)*12 # =24

model.forecasts_ARIMA_monthly_yearly <-forecast(model.bic_monthlyyearly, h=test.size)


# Merge the two data frames on the 'index' column, and handle missing values with 0
selected_df_monthly_yearly <- merge(model.forecasts_ARIMA_monthly_yearly, test_data_seasonally_adjusted, by = "index", all.x = TRUE) %>%
  select(index, season_adjust.y , .mean) %>%
  rename(predicted = .mean, current_value = season_adjust.y)

# Calculate the squared differences between 'predicted' and 'current_value'
selected_df_monthly_yearly$diff_squared <- (selected_df_monthly_yearly$predicted - selected_df_monthly_yearly$current_value)^2

# Calculate the RMSE
rmse_monthly_yearly <- sqrt(mean(selected_df_monthly_yearly$diff_squared))

# Print the RMSE
print(paste("ARIMA model Root Mean Squared Error (RMSE):", rmse_monthly_yearly))

```
```{r train ARIMA non-seasonal model, include = FALSE}
# Developing model from non-seasonal adjusted dataset
model.bic_weekly_ARIMA <-train_data_non_season %>%
  model(fable::ARIMA(value ~ 0:1 + pdq(0:4,0:2,0:4) + 
                       PDQ(0:5,0:3,0:5, period=12),
                     ic="bic", stepwise=F, greedy=F))

 model.bic_weekly_ARIMA %>%
  report()
```

```{r forecast non seasonal arima model, echo=FALSE, message=FALSE}

test.size = (2024-2022) * 4 * 12 # = 96?

model.forecasts_ARIMA_weekly <-forecast(model.bic_weekly_ARIMA, h=test.size)

# Merge the two data frames on the 'index' column, and handle missing values with 0
merged_df_weekly <- merge(model.forecasts_ARIMA_weekly, test_data_non_season, by = "time_index", all.x = TRUE)

# Select the desired columns and rename them if needed
selected_df_weekly <- merged_df_weekly %>%
  select(time_index, value.y , .mean) %>%
  rename(predicted = .mean, current_value = value.y)

# Calculate the squared differences between 'predicted' and 'current_value'
selected_df_weekly$diff_squared <- (selected_df_weekly$predicted - selected_df_weekly$current_value)^2

# Calculate the RMSE
rmse_yearly_weekly_non_season <- sqrt(mean(selected_df_weekly$diff_squared))

```


*Consider adding the equations of ARIMA seasonal and non seasonal here*
*Consider adding plots next to each other here* @Mingxi

$equation \space here$

```{r , echo=FALSE}
kable(
  data.frame('model_type' = c('arima seasonal','arima non seasonal'),
           'model equation' = c('ARIMA(0,2,2)(4,0,0)[12]','ARIMA(2,1,4) w/ drift '),
           'BIC score' = c(54.82, 3463.76),
           'test RMSE' = c(rmse_monthly_yearly, rmse_yearly_weekly_non_season)
           ),
  caption = "ARIMA comparison table"
)
```


*add analysis of ARIMA's here. what can we conclude?*

Next, we fit a polynomial time-trend model to the seasonally-adjusted series and compare its performance to the ARIMA model. Using the TSLM package, we created our best fit model.
```{r train linear seasonal adjusted model, echo = FALSE }
train_data_seasonally_adjusted %>% 
  model(model_trend =  TSLM(season_adjust ~ trend() + season() )) -> fit_linear_season_adjusted_yeary_monthly
```



```{r forecast linear seasonal adjusted model, echo=FALSE}
test.size = (2024-2022)*12 #24

model.forecasts__season_linear_yearly_monthly <-forecast(fit_linear_season_adjusted_yeary_monthly, h=test.size)

# Merge the two data frames on the 'index' column, and handle missing values with 0
merged_df_yearly_monthly_linear <- merge(model.forecasts__season_linear_yearly_monthly, test_data_seasonally_adjusted, by = "index", all.x = TRUE)

# Select the desired columns and rename them if needed
selected_df_yearly_monthly_linear <- merged_df_yearly_monthly_linear %>%
  select(index, season_adjust.y , .mean) %>%
  rename(predicted = .mean, current_value = season_adjust.y)

# Calculate the squared differences between 'predicted' and 'current_value'
selected_df_yearly_monthly_linear$diff_squared <- (selected_df_yearly_monthly_linear$predicted - selected_df_yearly_monthly_linear$current_value)^2

# Calculate the RMSE
rmse_seasonal_yearly_monthly <- sqrt(mean(selected_df_yearly_monthly_linear$diff_squared))

```


```{r ,echo=FALSE}
kable(
  data.frame('model_type' = c('ARIMA seasonl', 'linear seasonal'),
           'model equation' = c('equation here','equation here'),
           'BIC score' = c('fix', 'fix'),
           'test RMSE' = c("rmse_seasonal_yearly_monthly", "rmse_weekly_non_seasonal")
           )
  , caption = 'linear model comparison'
)
```





### (3 points) Task Part 6b: How bad could it get?
The best model we derived from Part 5b was the ARIMA model. Utilizing this model, we projected CO2 levels on the original weekly dataset which is a non-seasonally adjusted data. Our analysis indicated that CO2 levels are predicted to reach 420 ppm in 2023, but are not expected to reach 500 ppm. We observed that in the year 3075, the upper boundary touched 500 ppm, but with low confidence. These predictions can be influenced by the data's aggregation level. For instance, weekly aggregated data may yield more vague predictions because the number of datapoints are larger resulting in higher noise and variability in data, whereas monthly aggregated data can provide slightly improved predictions. On examining the weekly level aggregated data, we noticed that the prediction boundary intervals curve downwards, which is not ideal because it captures too much noise and adds variability. However, with monthly level data, predictions are comparatively better, and the boundary intervals are narrower and upward. According to our analysis, the 500 ppm threshold is projected to be reached by the year 2050.

The predictions for 2122 is 425 with boundary limits of 310-555 in the weekly aggregated dataset. However, in the monthly aggregated dataset, the prediction for 2122 is 650 with narrower boundary levels.
Another factor that can impact these predictions is the evaluation metric used. In our analysis, we employed the Bayesian Information Criterion (BIC). If an alternative metric had been employed, the predictions might have varied. The use of BIC penalizes the data more, leading to a more conservative model selection that favors simpler models. As a result, the chosen model may be too simplistic to accurately capture the underlying patterns and relationships in the future unseen data. Hence, considering alternative evaluation metrics could potentially yield different or more accurate predictions.



```{r , echo=FALSE , fig.height=3}

# Year 2122 forcast and on Weekly Dataset

model_weekly_ARIMA_forecast <- fabletools::forecast(model.bic_weekly_ARIMA, h=5000)

model_weekly_ARIMA_forecast %>%
  autoplot(train_data_non_season) +
  labs(
    title = "Forecasts of weekly-aggregated CO2 levels up to 2122 using the ARIMA model",
    y = "CO2 Level", x = "Time"
  )
# 425 with boundary 310-555
```


```{r , echo = FALSE, fig.height=3}
# Year 2122 forcast and on Weekly Dataset

model_yearly_ARIMA_forecast <- fabletools::forecast(model.bic_monthlyyearly, h=1500)

model_yearly_ARIMA_forecast %>%
  autoplot(train_data_seasonally_adjusted) +
  labs(
    title = "Forecasts of CO2 level Up To 2122 using ARIMA model",
    y = "CO2 Level", x = "Time")
```


```{r , echo=FALSE}
# predicted co2 value 420 
# Whether 420ppm CO2 present in data or not?
# period for [Jan 2022 to Dec 2122]

# Forecasts of Section2 ARIMA model for the period [Jan 2022 to Dec 2122]

test.size = 12784 # weekly time series unit

model.forecasts_ARIMA_weekly <-forecast(model.bic_weekly_ARIMA, h=test.size)

# Check if there is any value near 420 (within a range of +/- 10) in the .mean column
value_420ppm <- any(abs(model.forecasts_ARIMA_weekly$.mean - 420) <= 10)

# **420 ppm CO2 level is not present in the forecasted data until the year 2122. Hence upper and lower bound doesnt # exist either.**

```


 
```{r, include=FALSE}
# predicted co2 value 500
# Whether 500ppm CO2 present in data or not?
# period for [Jan 2022 to Dec 2122]

# Assuming your model.forecasts_ARIMA_weekly contains the columns 'date' and '.mean'

# Check if there is any value near 420 (within a range of +/- 10) in the .mean column
value_500ppm <- any(abs(model.forecasts_ARIMA_weekly$.mean - 500) <= 10)


# **500 ppm CO2 level is not present in the forecasted data until the year 2122.Hence upper and lower bound doesnt # exist either.**
```


```{r echo =FALSE}
# ## Confidence interval
model.forecasts_ARIMA_weekly_confidence_interval <-model.forecasts_ARIMA_weekly %>% mutate(upper=quantile(.mean,0.95),lower=quantile(.mean,0.05))
```


\appendix
\section{Appendix: Model Robustness}


While the most plausible model that we estimate is reported in the main, "Modeling" section, in this appendix to the article we examine alternative models. Here, our intent is to provide a skeptic that does not accept our assessment of this model as an ARIMA of order (1,2,3) an understanding of model forecasts under alternative scenarios. 

Modern data pipeline code:
<!---
```{r weekly load appendix}
co2_present_raw=read.csv("https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_weekly_mlo.csv",skip=51)
co2_present <- co2_present_raw %>% 
  mutate(time_index=lubridate::make_date(year,month,day)) %>% 
  dplyr::select(time_index,average) %>%
  as_tsibble(index = time_index) %>%
  mutate(average =replace(average,average<=-999,NA)) %>%
  mutate(average = na.approx(average))
```
```{r monthly load appendix, include = FALSE}

co2_present_monthly_raw <- "https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.csv"

co2_present_raw=read.csv(co2_present_monthly_raw,skip=56)

co2_present_month <- co2_present_raw %>% 
  mutate(time_index=lubridate::make_date(year,month)) %>% 
  dplyr::select(time_index,average) %>%
  as_tsibble(index = time_index) %>%
  mutate(average =replace(average,average<=-999,NA)) %>%
  mutate(average = na.approx(average))



glimpse(co2_present)
glimpse(co2_present_month)
```
--->
